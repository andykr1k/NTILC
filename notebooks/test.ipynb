{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5cc13660",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/scratch4/home/akrik/base/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /scratch4/home/akrik/NTILC\n",
            "PyTorch version: 2.9.1+cu128\n",
            "CUDA available: True\n",
            "CUDA device: NVIDIA H100 80GB HBM3\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Load and use the trained autoencoder model.\n",
        "\"\"\"\n",
        "import sys\n",
        "from pathlib import Path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import torch\n",
        "from models.autoencoder import ToolInvocationAutoencoder\n",
        "from training.config import AutoencoderConfig\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "305b10b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found checkpoint at: /scratch4/home/akrik/NTILC/checkpoints/best_model.pt\n"
          ]
        }
      ],
      "source": [
        "# Configuration: Set the path to your trained model checkpoint\n",
        "# Default is ./checkpoints/best_model.pt, but you can change this\n",
        "CHECKPOINT_PATH = project_root / \"checkpoints\" / \"best_model.pt\"\n",
        "\n",
        "# If the default path doesn't exist, try to find it\n",
        "if not CHECKPOINT_PATH.exists():\n",
        "    print(f\"Warning: {CHECKPOINT_PATH} not found. Please update CHECKPOINT_PATH.\")\n",
        "    print(\"Looking for checkpoints in common locations...\")\n",
        "    \n",
        "    # Try alternative locations\n",
        "    alt_paths = [\n",
        "        project_root / \"checkpoints\" / \"best_model.pt\",\n",
        "        Path(\"./checkpoints/best_model.pt\"),\n",
        "        Path(\"../checkpoints/best_model.pt\"),\n",
        "    ]\n",
        "    \n",
        "    found = False\n",
        "    for alt_path in alt_paths:\n",
        "        if alt_path.exists():\n",
        "            CHECKPOINT_PATH = alt_path\n",
        "            print(f\"Found checkpoint at: {CHECKPOINT_PATH}\")\n",
        "            found = True\n",
        "            break\n",
        "    \n",
        "    if not found:\n",
        "        print(\"No checkpoint found. Please specify CHECKPOINT_PATH manually.\")\n",
        "else:\n",
        "    print(f\"Found checkpoint at: {CHECKPOINT_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5258f5f4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading checkpoint from /scratch4/home/akrik/NTILC/checkpoints/best_model.pt...\n",
            "\n",
            "Saved model configuration:\n",
            "  embedding_dim: 256\n",
            "  encoder_model: google/flan-t5-base\n",
            "  decoder_model: google/flan-t5-base\n",
            "  pooling_strategy: attention\n",
            "  max_length: 128\n",
            "  dropout: 0.1\n",
            "  freeze_encoder: False\n",
            "  freeze_decoder: False\n",
            "  batch_size: 64\n",
            "  learning_rate: 1e-05\n",
            "  weight_decay: 0.01\n",
            "  num_epochs: 50\n",
            "  warmup_steps: 1000\n",
            "  gradient_clip: 0.5\n",
            "  use_lr_scheduler: True\n",
            "  use_gradient_checkpointing: True\n",
            "  torch_dtype: bfloat16\n",
            "  num_train_samples: 100000\n",
            "  num_val_samples: 10000\n",
            "  num_test_samples: 10000\n",
            "  output_dir: ./checkpoints\n",
            "  log_dir: ./logs\n",
            "  data_dir: ./data\n",
            "  log_interval: 100\n",
            "  eval_interval: 1000\n",
            "  save_interval: 5000\n",
            "  use_wandb: True\n",
            "  wandb_project: ntilc\n",
            "  wandb_entity: andykr1k\n",
            "  wandb_run_name: None\n",
            "  early_stopping_patience: 7\n",
            "  early_stopping_min_delta: 0.001\n",
            "\n",
            "Validation metrics from training:\n",
            "  exact_match_accuracy: 0.0476\n",
            "  tool_accuracy: 0.9966\n",
            "  param_str_accuracy: 0.1305\n",
            "  param_int_accuracy: 0.0216\n",
            "  embedding_mean_norm: 15.6875\n",
            "  embedding_std_norm: 0.0286\n",
            "  embedding_min_norm: 15.6875\n",
            "  embedding_max_norm: 15.7500\n",
            "  embedding_mean_variance: 0.1348\n",
            "  embedding_std_variance: 0.0737\n",
            "  embedding_mean_per_dim: 0.0000\n",
            "  embedding_std_per_dim: 0.3555\n",
            "  file_read/count: 1666.0000\n",
            "  file_read/exact_match_accuracy: 0.0000\n",
            "  file_read/tool_accuracy: 1.0000\n",
            "  web_fetch/count: 1666.0000\n",
            "  web_fetch/exact_match_accuracy: 0.0000\n",
            "  web_fetch/tool_accuracy: 1.0000\n",
            "  calculate/count: 1667.0000\n",
            "  calculate/exact_match_accuracy: 0.2855\n",
            "  calculate/tool_accuracy: 1.0000\n",
            "  send_email/count: 1667.0000\n",
            "  send_email/exact_match_accuracy: 0.0000\n",
            "  send_email/tool_accuracy: 0.9796\n",
            "  search/count: 1667.0000\n",
            "  search/exact_match_accuracy: 0.0000\n",
            "  search/tool_accuracy: 1.0000\n",
            "  database_query/count: 1667.0000\n",
            "  database_query/exact_match_accuracy: 0.0000\n",
            "  database_query/tool_accuracy: 1.0000\n",
            "\n",
            "Model was trained for 3 epochs\n"
          ]
        }
      ],
      "source": [
        "# Load the checkpoint\n",
        "print(f\"Loading checkpoint from {CHECKPOINT_PATH}...\")\n",
        "checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')\n",
        "\n",
        "# Extract saved configuration\n",
        "saved_config_dict = checkpoint.get('config', {})\n",
        "print(\"\\nSaved model configuration:\")\n",
        "for key, value in saved_config_dict.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Create config object from saved config\n",
        "config = AutoencoderConfig(**saved_config_dict)\n",
        "\n",
        "# Print validation metrics if available\n",
        "if 'val_metrics' in checkpoint:\n",
        "    print(\"\\nValidation metrics from training:\")\n",
        "    for key, value in checkpoint['val_metrics'].items():\n",
        "        if isinstance(value, (int, float)):\n",
        "            print(f\"  {key}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "print(f\"\\nModel was trained for {checkpoint.get('epoch', 'unknown')} epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4ac46e8e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing model...\n",
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model weights...\n",
            "Model loaded successfully!\n",
            "Model parameters: 360,949,633\n",
            "Trainable parameters: 360,949,633\n"
          ]
        }
      ],
      "source": [
        "# Initialize model with saved configuration\n",
        "print(\"Initializing model...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = ToolInvocationAutoencoder(\n",
        "    embedding_dim=config.embedding_dim,\n",
        "    encoder_model=config.encoder_model,\n",
        "    decoder_model=config.decoder_model,\n",
        "    pooling_strategy=config.pooling_strategy,\n",
        "    max_length=config.max_length,\n",
        "    dropout=config.dropout,\n",
        "    freeze_encoder=config.freeze_encoder,\n",
        "    freeze_decoder=config.freeze_decoder,\n",
        "    torch_dtype=config.torch_dtype,\n",
        "    use_gradient_checkpointing=config.use_gradient_checkpointing\n",
        ")\n",
        "\n",
        "# Load model weights\n",
        "print(\"Loading model weights...\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model = model.to(device)\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "95660852",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing model with example tool invocations:\n",
            "\n",
            "1. search(query='machine learning', max_results=10)\n",
            "2. calculate(expression='2 + 2 * 3')\n",
            "3. database_query(table='users', limit=50)\n",
            "4. send_email(to='user@example.com', subject='Test', body='Hello world')\n",
            "5. web_fetch(url='https://example.com', method='GET')\n",
            "6. file_read(path='/path/to/file.txt')\n"
          ]
        }
      ],
      "source": [
        "# Example tool invocations to test\n",
        "test_tool_calls = [\n",
        "    \"search(query='machine learning', max_results=10)\",\n",
        "    \"calculate(expression='2 + 2 * 3')\",\n",
        "    \"database_query(table='users', limit=50)\",\n",
        "    \"send_email(to='user@example.com', subject='Test', body='Hello world')\",\n",
        "    \"web_fetch(url='https://example.com', method='GET')\",\n",
        "    \"file_read(path='/path/to/file.txt')\",\n",
        "]\n",
        "\n",
        "print(\"Testing model with example tool invocations:\\n\")\n",
        "for i, tool_call in enumerate(test_tool_calls, 1):\n",
        "    print(f\"{i}. {tool_call}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "731adbd8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding tool calls to embeddings...\n",
            "Embeddings shape: torch.Size([6, 256])\n",
            "Embedding dimension: 256\n",
            "\n",
            "First embedding stats:\n",
            "  Min: -2.8125\n",
            "  Max: 2.6094\n",
            "  Mean: -0.0000\n",
            "  Std: 0.9844\n"
          ]
        }
      ],
      "source": [
        "# Test encoding: Convert tool calls to embeddings\n",
        "print(\"Encoding tool calls to embeddings...\")\n",
        "with torch.no_grad():\n",
        "    embeddings = model.encode(test_tool_calls)\n",
        "\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")  # Should be (batch_size, embedding_dim)\n",
        "print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
        "print(f\"\\nFirst embedding stats:\")\n",
        "print(f\"  Min: {embeddings[0].min().item():.4f}\")\n",
        "print(f\"  Max: {embeddings[0].max().item():.4f}\")\n",
        "print(f\"  Mean: {embeddings[0].mean().item():.4f}\")\n",
        "print(f\"  Std: {embeddings[0].std().item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cf1cfb4b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reconstructing tool calls (encode -> decode)...\n",
            "\n",
            "1. ✗\n",
            "   Original:     search(query='machine learning', max_results=10)\n",
            "   Reconstructed: search(query='digital computing', max_results=7)\n",
            "\n",
            "2. ✗\n",
            "   Original:     calculate(expression='2 + 2 * 3')\n",
            "   Reconstructed: calculate(expression='2 + 2')\n",
            "\n",
            "3. ✗\n",
            "   Original:     database_query(table='users', filter={'age': {'>': 25}}, limit=50)\n",
            "   Reconstructed: '', '', '', ''\n",
            "\n",
            "4. ✗\n",
            "   Original:     send_email(to='user@example.com', subject='Test', body='Hello world')\n",
            "   Reconstructed: send me the following information: name, email, password, subject, and subject.\n",
            "\n",
            "5. ✗\n",
            "   Original:     web_fetch(url='https://example.com', method='GET')\n",
            "   Reconstructed: web_fetch(url='https://api.example.com/get', method='GET')\n",
            "\n",
            "6. ✗\n",
            "   Original:     file_read(path='/path/to/file.txt')\n",
            "   Reconstructed: file_read(path='/home/files/tmp/files/tmp/files/files/path/path/files/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test reconstruction: Encode then decode\n",
        "print(\"Reconstructing tool calls (encode -> decode)...\\n\")\n",
        "reconstructed = model.reconstruct(test_tool_calls)\n",
        "\n",
        "for i, (original, recon) in enumerate(zip(test_tool_calls, reconstructed), 1):\n",
        "    match = \"✓\" if original == recon else \"✗\"\n",
        "    print(f\"{i}. {match}\")\n",
        "    print(f\"   Original:     {original}\")\n",
        "    print(f\"   Reconstructed: {recon}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "94696f39",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoding embeddings back to tool calls...\n",
            "\n",
            "1. ✗\n",
            "   Original: search(query='machine learning', max_results=10)\n",
            "   Decoded:  search(query='digital computing', max_results=7)\n",
            "\n",
            "2. ✗\n",
            "   Original: calculate(expression='2 + 2 * 3')\n",
            "   Decoded:  calculate(expression='2 + 2')\n",
            "\n",
            "3. ✗\n",
            "   Original: database_query(table='users', limit=50)\n",
            "   Decoded:  database_query(query='database', search='database', data='database', time='5')\n",
            "\n",
            "4. ✗\n",
            "   Original: send_email(to='user@example.com', subject='Test', body='Hello world')\n",
            "   Decoded:  send me the following information: name, email, password, subject, and subject.\n",
            "\n",
            "5. ✗\n",
            "   Original: web_fetch(url='https://example.com', method='GET')\n",
            "   Decoded:  web_fetch(url='https://api.example.com/get', method='GET')\n",
            "\n",
            "6. ✗\n",
            "   Original: file_read(path='/path/to/file.txt')\n",
            "   Decoded:  file_read(path='/home/files/tmp/files/tmp/files/files/path/path/files/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path/path\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test decoding: Decode embeddings back to tool calls\n",
        "print(\"Decoding embeddings back to tool calls...\\n\")\n",
        "decoded = model.decode(embeddings)\n",
        "\n",
        "for i, (original, decoded_call) in enumerate(zip(test_tool_calls, decoded), 1):\n",
        "    match = \"✓\" if original == decoded_call else \"✗\"\n",
        "    print(f\"{i}. {match}\")\n",
        "    print(f\"   Original: {original}\")\n",
        "    print(f\"   Decoded:  {decoded_call}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1cb27108",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reconstruction Accuracy: 0.00% (0/6)\n"
          ]
        }
      ],
      "source": [
        "# Compute reconstruction accuracy\n",
        "exact_matches = sum(1 for orig, recon in zip(test_tool_calls, reconstructed) if orig == recon)\n",
        "accuracy = exact_matches / len(test_tool_calls)\n",
        "\n",
        "print(f\"Reconstruction Accuracy: {accuracy:.2%} ({exact_matches}/{len(test_tool_calls)})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b0cc3d29",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing pairwise cosine similarity between embeddings...\n",
            "\n",
            "Cosine similarity matrix:\n",
            "           1     2     3     4     5     6\n",
            "   1   0.996 0.820 0.906 0.855 0.852 0.832\n",
            "   2   0.820 0.996 0.809 0.777 0.801 0.785\n",
            "   3   0.906 0.809 1.000 0.875 0.871 0.859\n",
            "   4   0.855 0.777 0.875 1.000 0.914 0.891\n",
            "   5   0.852 0.801 0.871 0.914 1.000 0.898\n",
            "   6   0.832 0.785 0.859 0.891 0.898 1.000\n"
          ]
        }
      ],
      "source": [
        "# Example: Compute similarity between embeddings\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"Computing pairwise cosine similarity between embeddings...\\n\")\n",
        "with torch.no_grad():\n",
        "    # Normalize embeddings for cosine similarity\n",
        "    normalized_embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "    similarity_matrix = torch.mm(normalized_embeddings, normalized_embeddings.t())\n",
        "\n",
        "print(\"Cosine similarity matrix:\")\n",
        "print(\"      \", end=\"\")\n",
        "for i in range(len(test_tool_calls)):\n",
        "    print(f\"{i+1:>6}\", end=\"\")\n",
        "print()\n",
        "for i in range(len(test_tool_calls)):\n",
        "    print(f\"  {i+1:2d}  \", end=\"\")\n",
        "    for j in range(len(test_tool_calls)):\n",
        "        sim = similarity_matrix[i, j].item()\n",
        "        print(f\"{sim:6.3f}\", end=\"\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "93937bfd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interpolating between two tool calls...\n",
            "\n",
            "Tool 1: search(query='machine learning', max_results=10)\n",
            "Tool 2: database_query(table='users', limit=50)\n",
            "\n",
            "α=0.00: search(query='digital computing', max_results=7)\n",
            "α=0.25: search(query='digital computing', max_results=10)\n",
            "α=0.50: search(query='digital computing', max_results=10)\n",
            "α=0.75: search(query='shortest search', max_result=10)\n",
            "α=1.00: database_query(query='database', search='database', data='database', time='5')\n"
          ]
        }
      ],
      "source": [
        "# Example: Interpolate between two tool calls\n",
        "print(\"Interpolating between two tool calls...\\n\")\n",
        "\n",
        "# Select two tool calls\n",
        "idx1, idx2 = 0, 2\n",
        "tool1 = test_tool_calls[idx1]\n",
        "tool2 = test_tool_calls[idx2]\n",
        "\n",
        "print(f\"Tool 1: {tool1}\")\n",
        "print(f\"Tool 2: {tool2}\\n\")\n",
        "\n",
        "# Get embeddings\n",
        "emb1 = embeddings[idx1:idx1+1]\n",
        "emb2 = embeddings[idx2:idx2+1]\n",
        "\n",
        "# Interpolate\n",
        "num_steps = 5\n",
        "interpolated_tool_calls = []\n",
        "for alpha in torch.linspace(0, 1, num_steps):\n",
        "    interp_emb = (1 - alpha) * emb1 + alpha * emb2\n",
        "    decoded = model.decode(interp_emb)\n",
        "    interpolated_tool_calls.append(decoded[0])\n",
        "    print(f\"α={alpha:.2f}: {decoded[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5e3610bc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading test data from /scratch4/home/akrik/NTILC/data/test_data.txt...\n",
            "Loaded 10000 test samples\n",
            "\n",
            "Evaluating on 100 samples...\n",
            "\n",
            "Test Metrics:\n",
            "  exact_match_accuracy: 0.0600\n",
            "  tool_accuracy: 0.9800\n",
            "  param_str_accuracy: 0.1751\n",
            "  param_int_accuracy: 0.0333\n",
            "  embedding_mean_norm: 15.6875\n",
            "  embedding_std_norm: 0.0302\n",
            "  embedding_min_norm: 15.6875\n",
            "  embedding_max_norm: 15.7500\n",
            "  embedding_mean_variance: 0.1387\n",
            "  embedding_std_variance: 0.0776\n",
            "  embedding_mean_per_dim: -0.0000\n",
            "  embedding_std_per_dim: 0.3594\n"
          ]
        }
      ],
      "source": [
        "# Optional: Load and evaluate on test dataset\n",
        "from training.data_generator import ToolInvocationGenerator, DataGeneratorConfig\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from evaluation.metrics import compute_metrics\n",
        "\n",
        "# Load test data if available\n",
        "test_data_path = project_root / \"data\" / \"test_data.txt\"\n",
        "if test_data_path.exists():\n",
        "    print(f\"Loading test data from {test_data_path}...\")\n",
        "    data_config = DataGeneratorConfig()\n",
        "    generator = ToolInvocationGenerator(data_config)\n",
        "    test_tool_calls = generator.load_dataset(str(test_data_path))\n",
        "    \n",
        "    print(f\"Loaded {len(test_tool_calls)} test samples\")\n",
        "    \n",
        "    # Evaluate on a subset (first 100 for quick testing)\n",
        "    num_samples = min(100, len(test_tool_calls))\n",
        "    test_subset = test_tool_calls[:num_samples]\n",
        "    \n",
        "    print(f\"\\nEvaluating on {num_samples} samples...\")\n",
        "    reconstructed = model.reconstruct(test_subset)\n",
        "    embeddings = model.encode(test_subset)\n",
        "    \n",
        "    # Compute metrics\n",
        "    metrics = compute_metrics(test_subset, reconstructed, embeddings)\n",
        "    \n",
        "    print(\"\\nTest Metrics:\")\n",
        "    for key, value in metrics.items():\n",
        "        if isinstance(value, (int, float)):\n",
        "            print(f\"  {key}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"  {key}: {value}\")\n",
        "else:\n",
        "    print(f\"Test data not found at {test_data_path}\")\n",
        "    print(\"Skipping test evaluation. Run training script to generate test data.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
